name: Databricks Enterprise Deployment

on:
  workflow_call:
    inputs:
      environment:
        required: true
        type: string
      artifact_types:
        required: true
        type: string
        description: "notebooks|wheel|libraries|all"
      project_path:
        required: true
        type: string
      databricks_path:
        required: true
        type: string
      test_type:
        required: false
        type: string
        default: 'unit'
        description: "unit|integration|both"

    secrets:
      DATABRICKS_HOST:
        required: true
      DATABRICKS_TOKEN:
        required: true
      DATABRICKS_CLUSTER_ID:
        required: true

jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run Snyk Security Scan
        uses: snyk/actions/python@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
      - name: Run OWASP Dependency Check
        run: |
          curl -s https://raw.githubusercontent.com/jeremylong/DependencyCheck/main/install.sh | bash
          ./dependency-check/bin/dependency-check.sh --project "Databricks Deployment" --scan ${{ inputs.project_path }}

  test:
    needs: security-scan
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9]
    steps:
      - uses: actions/checkout@v3
      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
      - name: Install Dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-integration black isort pylint mypy
      - name: Code Quality and Lint Checks
        run: |
          black --check ${{ inputs.project_path }}
          isort --check ${{ inputs.project_path }}
          pylint ${{ inputs.project_path }} --fail-under=8.5
          mypy ${{ inputs.project_path }}
      - name: Unit Tests
        if: inputs.test_type == 'unit' || inputs.test_type == 'both'
        run: pytest tests/unit --cov=${{ inputs.project_path }}
      - name: Integration Tests
        if: inputs.test_type == 'integration' || inputs.test_type == 'both'
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: pytest tests/integration
      - name: Upload Coverage Report
        uses: actions/upload-artifact@v3
        with:
          name: coverage-report
          path: htmlcov/

  build:
    needs: test
    if: inputs.artifact_types == 'wheel' || inputs.artifact_types == 'all'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Build Wheel
        run: |
          pip install build
          python -m build
      - name: Version Tagging
        run: |
          BUILD_ID=$(date +"%Y%m%d%H%M%S")
          echo "##[group]Tagging Build with ID: $BUILD_ID"
          git tag -a v$BUILD_ID -m "Build version for ${{ inputs.environment }}"
          git push origin --tags
      - uses: actions/upload-artifact@v3
        with:
          name: dist
          path: dist/*.whl

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment }}
    steps:
      - uses: actions/checkout@v3
      - name: Configure Databricks CLI
        run: |
          pip install databricks-cli
          echo "DATABRICKS_HOST=${{ secrets.DATABRICKS_HOST }}" >> $GITHUB_ENV
          echo "DATABRICKS_TOKEN=${{ secrets.DATABRICKS_TOKEN }}" >> $GITHUB_ENV
          databricks configure --token

      - name: Deploy to Databricks
        run: |
          echo "Deploying artifacts to ${{ inputs.databricks_path }}"
          databricks workspace import_dir ${{ inputs.project_path }} ${{ inputs.databricks_path }}

      - name: Install Dependencies on Cluster
        if: inputs.artifact_types == 'libraries' || inputs.artifact_types == 'all'
        run: |
          databricks libraries install \
            --cluster-id ${{ secrets.DATABRICKS_CLUSTER_ID }} \
            --requirements requirements.txt

      - name: Deploy Wheel Package
        if: inputs.artifact_types == 'wheel' || inputs.artifact_types == 'all'
        run: |
          databricks fs cp dist/*.whl dbfs:/FileStore/${{ inputs.project_path }}/dist/
          databricks libraries install \
            --cluster-id ${{ secrets.DATABRICKS_CLUSTER_ID }} \
            --whl dbfs:/FileStore/${{ inputs.project_path }}/dist/*.whl

  smoke-test:
    needs: deploy
    runs-on: ubuntu-latest
    steps:
      - name: Run Test Notebook
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          databricks jobs run-now \
            --job-id ${{ secrets.SMOKE_TEST_JOB_ID }}
